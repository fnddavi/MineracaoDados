{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92466d8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO kernel falhou ao iniciar porque o ambiente do Python ‚ÄúPython 3.12.3‚Äù n√£o est√° mais dispon√≠vel. Considere selecionar outro kernel ou atualizar a lista de Ambientes do Python."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CARREGAR E PREPARAR OS DADOS\n",
    "# ============================================================================\n",
    "\n",
    "# Carregar dataset\n",
    "df = pd.read_csv('breast-cancer.csv')\n",
    "\n",
    "# Substituir '?' por NaN\n",
    "df_clean = df.copy()\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        df_clean[col] = df_clean[col].replace('?', np.nan)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ü§ñ QUEST√ÉO 6 - CLASSIFICA√á√ÉO (Seguindo EXATAMENTE as instru√ß√µes)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Separar features e target\n",
    "X = df_clean.drop('Class', axis=1)\n",
    "y = df_clean['Class']\n",
    "\n",
    "# Codificar a vari√°vel target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"üìä Dimens√µes:\")\n",
    "print(f\"   ‚Ä¢ X (features): {X.shape}\")\n",
    "print(f\"   ‚Ä¢ y (target): {y.shape}\")\n",
    "print(f\"   ‚Ä¢ Classes: {np.unique(y, return_counts=True)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# M√âTODO 1: EXATAMENTE como a professora exemplificou\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù M√âTODO 1: Aplicando OneHotEncoder EXATAMENTE como no exemplo da professora\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identificar colunas categ√≥ricas (todas exceto 'deg-malig' que √© num√©rica)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"üìã Colunas categ√≥ricas (que ser√£o convertidas para bin√°rio):\")\n",
    "for col in categorical_cols:\n",
    "    unique_vals = X[col].dropna().unique()[:5]  # Mostrar primeiros 5 valores √∫nicos\n",
    "    print(f\"   ‚Ä¢ {col}: {len(X[col].dropna().unique())} valores √∫nicos, ex: {list(unique_vals)}\")\n",
    "\n",
    "# PASSO 1: Substituir valores ausentes pela MODA\n",
    "print(\"\\nüîß PASSO 1: Substituindo valores ausentes pela MODA...\")\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().any():\n",
    "        moda = X[col].mode()[0] if not X[col].mode().empty else 'unknown'\n",
    "        X[col] = X[col].fillna(moda)\n",
    "        print(f\"   ‚Ä¢ {col}: substitu√≠dos {X[col].isnull().sum()} valores pela moda '{moda}'\")\n",
    "\n",
    "# Verificar se ainda h√° valores ausentes\n",
    "print(f\"\\n‚úÖ Ap√≥s imputa√ß√£o pela moda: {X.isnull().sum().sum()} valores ausentes restantes\")\n",
    "\n",
    "# PASSO 2: Aplicar OneHotEncoder EXATAMENTE como no exemplo da professora\n",
    "print(\"\\nüîß PASSO 2: Aplicando OneHotEncoder...\")\n",
    "print(\"   encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\")\n",
    "\n",
    "# Criar o encoder exatamente como no exemplo\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "\n",
    "# Aplicar transforma√ß√£o (apenas nas colunas categ√≥ricas)\n",
    "# Primeiro, vamos codificar apenas as colunas categ√≥ricas\n",
    "X_categorical = X[categorical_cols]\n",
    "\n",
    "# Fit e transform\n",
    "print(\"   X_encoded = encoder.fit_transform(X_categorical).toarray()\")\n",
    "X_encoded = encoder.fit_transform(X_categorical).toarray()\n",
    "\n",
    "print(f\"\\nüìä Resultado da codifica√ß√£o:\")\n",
    "print(f\"   ‚Ä¢ Forma original de X_categorical: {X_categorical.shape}\")\n",
    "print(f\"   ‚Ä¢ Forma ap√≥s OneHotEncoder: {X_encoded.shape}\")\n",
    "print(f\"   ‚Ä¢ N√∫mero de features bin√°rias criadas: {X_encoded.shape[1]}\")\n",
    "\n",
    "# Agora, precisamos combinar com as colunas num√©ricas (deg-malig)\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nüî¢ Colunas num√©ricas (n√£o convertidas para bin√°rio): {numeric_cols}\")\n",
    "\n",
    "if numeric_cols:\n",
    "    X_numeric = X[numeric_cols].values\n",
    "    # Concatenar features num√©ricas com features codificadas\n",
    "    X_final = np.hstack([X_numeric, X_encoded])\n",
    "    print(f\"   ‚Ä¢ Forma final de X (num√©ricas + categ√≥ricas codificadas): {X_final.shape}\")\n",
    "else:\n",
    "    X_final = X_encoded\n",
    "\n",
    "# ============================================================================\n",
    "# CLASSIFICA√á√ÉO COM CROSS-VALIDATION (10 FOLDS)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ CLASSIFICA√á√ÉO COM CROSS-VALIDATION (10 FOLDS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Definir os classificadores\n",
    "j48 = DecisionTreeClassifier(random_state=42, criterion='entropy')\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Configurar cross-validation (10 folds)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nüîß Configura√ß√£o da valida√ß√£o cruzada:\")\n",
    "print(f\"   ‚Ä¢ N√∫mero de folds: 10\")\n",
    "print(f\"   ‚Ä¢ Total de inst√¢ncias: {len(X_final)}\")\n",
    "print(f\"   ‚Ä¢ Total de features: {X_final.shape[1]}\")\n",
    "\n",
    "# Avaliar J48\n",
    "print(\"\\nüìä Avaliando J48 (√Årvore de Decis√£o)...\")\n",
    "j48_scores = cross_val_score(j48, X_final, y_encoded, cv=cv, scoring='accuracy')\n",
    "j48_mean = j48_scores.mean()\n",
    "j48_std = j48_scores.std()\n",
    "\n",
    "print(f\"   ‚Ä¢ Scores por fold: {j48_scores}\")\n",
    "print(f\"   ‚Ä¢ Acur√°cia m√©dia: {j48_mean:.4f} ({j48_mean*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Desvio padr√£o: {j48_std:.4f}\")\n",
    "\n",
    "# Avaliar Naive Bayes\n",
    "print(\"\\nüìä Avaliando Naive Bayes...\")\n",
    "nb_scores = cross_val_score(naive_bayes, X_final, y_encoded, cv=cv, scoring='accuracy')\n",
    "nb_mean = nb_scores.mean()\n",
    "nb_std = nb_scores.std()\n",
    "\n",
    "print(f\"   ‚Ä¢ Scores por fold: {nb_scores}\")\n",
    "print(f\"   ‚Ä¢ Acur√°cia m√©dia: {nb_mean:.4f} ({nb_mean*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Desvio padr√£o: {nb_std:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RESULTADO FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ RESULTADO FINAL - QUEST√ÉO 6\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìà DESEMPENHO DOS ALGORITMOS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Criar DataFrame para visualiza√ß√£o\n",
    "results_df = pd.DataFrame({\n",
    "    'Algoritmo': ['J48 (√Årvore de Decis√£o)', 'Naive Bayes'],\n",
    "    'Acur√°cia M√©dia': [j48_mean, nb_mean],\n",
    "    'Desvio Padr√£o': [j48_std, nb_std],\n",
    "    'Acur√°cia (%)': [f\"{j48_mean*100:.2f}%\", f\"{nb_mean*100:.2f}%\"]\n",
    "})\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Determinar o melhor algoritmo\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéñÔ∏è  MELHOR ALGORITMO:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if j48_mean > nb_mean:\n",
    "    print(f\"‚úÖ J48 (√Årvore de Decis√£o) apresentou o MELHOR resultado!\")\n",
    "    print(f\"   ‚Ä¢ Acur√°cia: {j48_mean*100:.2f}%\")\n",
    "    print(f\"   ‚Ä¢ Superioridade: {abs(j48_mean - nb_mean)*100:.2f}% sobre Naive Bayes\")\n",
    "elif nb_mean > j48_mean:\n",
    "    print(f\"‚úÖ Naive Bayes apresentou o MELHOR resultado!\")\n",
    "    print(f\"   ‚Ä¢ Acur√°cia: {nb_mean*100:.2f}%\")\n",
    "    print(f\"   ‚Ä¢ Superioridade: {abs(nb_mean - j48_mean)*100:.2f}% sobre J48\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Os dois algoritmos apresentaram resultados equivalentes!\")\n",
    "\n",
    "# Visualiza√ß√£o comparativa\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gr√°fico 1: Acur√°cia m√©dia\n",
    "plt.subplot(1, 2, 1)\n",
    "algorithms = ['J48', 'Naive Bayes']\n",
    "accuracies = [j48_mean, nb_mean]\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "\n",
    "bars = plt.bar(algorithms, accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.title('Acur√°cia M√©dia dos Algoritmos', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Acur√°cia', fontsize=12)\n",
    "plt.ylim([0, 1.0])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{acc:.3f}\\n({acc*100:.1f}%)',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Gr√°fico 2: Scores por fold\n",
    "plt.subplot(1, 2, 2)\n",
    "folds = range(1, 11)\n",
    "plt.plot(folds, j48_scores, 'o-', color='skyblue', linewidth=2, markersize=8, label='J48')\n",
    "plt.plot(folds, nb_scores, 's-', color='lightcoral', linewidth=2, markersize=8, label='Naive Bayes')\n",
    "plt.title('Scores por Fold (10-Fold CV)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Fold', fontsize=12)\n",
    "plt.ylabel('Acur√°cia', fontsize=12)\n",
    "plt.xticks(folds)\n",
    "plt.ylim([0, 1.0])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle('Compara√ß√£o de Algoritmos de Classifica√ß√£o', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
